1) Обеспечить покрытие автотестами данного апи GET https://api.nasa.gov/planetary/earth/imagery + краткое ревью спецификации\документации

Данное апи и описание к нему можно найти на сайте https://api.nasa.gov/ -> browse APIs -> Earth(tab)

2) Краткое описание по используемым библиотекам. Почему был выбран какой-то определенный фреймворк

3) Какие проблемы\мысли\идеи возникли во время работы с данным заданием



1) Документация достаточно скудная, в процессе тестирования выяснилось что существует еще две переменных,
    не указанных в спецификации 'address', 'dataset
    Не все эксепшены нормально обрабатываются, как например это произошло с переменными lat/lon,
    где при вводе некорректных значений ловим ошибку No imagery for specified date.
    что не соответсвует действительности
    
2) В основе был выбран behave изза возможности нормально описывать тестовые сценарии через gherkin. 
    Для репортинга был выбран allure, в целом стандартная практика.
    Для запросов использовалась библиотека requests совместно с типизацией через pydantic
    
3) Проблемы возникали изза обработки картинок, в целом работать со стримами не самое приятное занятие.
    Нет ограничений на dim переменную, что заставляет грустить, ведь есть разумные пределы
    Есть некая переменная cloud_score которая не делает ничего (что описано в документации). Таких переменных в запросе быть явно не должно
    Из того что нужно доделать, это аттачинг логов для allure.
    Было бы не плохо добавить кастомных exception и дооборачивать запросы в try...except
    Не совсем понятна логика разделения у api на два вида эксепшенов, ожидаемых и системных, где разная структура сообщений.
    